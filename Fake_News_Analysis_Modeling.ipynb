{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "423e590b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import string\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize, WhitespaceTokenizer\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import joblib\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e1ed7e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "Buzzfeed = pd.read_csv('data/Buzzfeed_data.csv')\n",
    "Buzzfeed_title = Buzzfeed.copy()\n",
    "Buzzfeed_body = Buzzfeed.copy()\n",
    "\n",
    "top1 = pd.read_csv('data/top1_fake_title.csv').head(5)  # top 5 fake title words\n",
    "top2 = pd.read_csv('data/top2_real_title.csv').head(5)  # top 5 real title words\n",
    "top3 = pd.read_csv('data/top3_fake_body.csv').head(5)   # top 5 fake body words\n",
    "top4 = pd.read_csv('data/top4_real_body.csv').head(5)   # top 5 real body words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "92165811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert top words to list\n",
    "fake_title_words = top1['word'].tolist()\n",
    "real_title_words = top2['word'].tolist()\n",
    "fake_body_words = top3['word'].tolist()\n",
    "real_body_words = top4['word'].tolist()\n",
    "    \n",
    "\n",
    "# Helper to count occurrences of a word\n",
    "# def count_word(text, word):\n",
    "#     if isinstance(text, str):\n",
    "#         return len(re.findall(rf'\\b{word}\\b', text))\n",
    "#     else:\n",
    "#         return 0\n",
    "\n",
    "def has_word(text, word):\n",
    "    if isinstance(text, str):\n",
    "        return 1 if re.search(rf'\\b{word}\\b', text) else 0\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ff250eb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>news_type</th>\n",
       "      <th>contain_movies</th>\n",
       "      <th>contain_images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Another Terrorist Attack in NYC…Why Are we STI...</td>\n",
       "      <td>On Saturday, September 17 at 8:30 pm EST, an e...</td>\n",
       "      <td>http://eaglerising.com</td>\n",
       "      <td>Real</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Donald Trump: Drugs a 'Very, Very Big Factor' ...</td>\n",
       "      <td>Less than a day after protests over the police...</td>\n",
       "      <td>http://abcn.ws</td>\n",
       "      <td>Real</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Obama To UN: ‘Giving Up Liberty, Enhances Secu...</td>\n",
       "      <td>Obama To UN: ‘Giving Up Liberty, Enhances Secu...</td>\n",
       "      <td>http://rightwingnews.com</td>\n",
       "      <td>Real</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trump vs. Clinton: A Fundamental Clash over Ho...</td>\n",
       "      <td>Getty Images Wealth Of Nations Trump vs. Clint...</td>\n",
       "      <td>http://politi.co</td>\n",
       "      <td>Real</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>President Obama Vetoes 9/11 Victims Bill, Sett...</td>\n",
       "      <td>President Obama today vetoed a bill that would...</td>\n",
       "      <td>http://abcn.ws</td>\n",
       "      <td>Real</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>Hillary’s TOP Donor Country Just Auctioned Off...</td>\n",
       "      <td>Hillary’s TOP Donor Country Just Auctioned Off...</td>\n",
       "      <td>http://rightwingnews.com</td>\n",
       "      <td>Fake</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>Cavuto Just Exposed Lester Holt's Lies During ...</td>\n",
       "      <td>Advertisement - story continues below\\n\\nThe f...</td>\n",
       "      <td>http://conservativetribune.com</td>\n",
       "      <td>Fake</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>The AP, In 2004, Said Your Boy Obama Was BORN ...</td>\n",
       "      <td>Well THAT’S Weird. If the Birther movement is ...</td>\n",
       "      <td>http://clashdaily.com</td>\n",
       "      <td>Fake</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>People Noticed Something Odd About Hillary's O...</td>\n",
       "      <td>\\n\\nThere’s a lot to be discussed about last n...</td>\n",
       "      <td>http://www.thepoliticalinsider.com</td>\n",
       "      <td>Fake</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>People Noticed Something Odd About Hillary’s O...</td>\n",
       "      <td>People Noticed Something Odd About Hillary’s O...</td>\n",
       "      <td>http://rightwingnews.com</td>\n",
       "      <td>Fake</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>182 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "0    Another Terrorist Attack in NYC…Why Are we STI...   \n",
       "1    Donald Trump: Drugs a 'Very, Very Big Factor' ...   \n",
       "2    Obama To UN: ‘Giving Up Liberty, Enhances Secu...   \n",
       "3    Trump vs. Clinton: A Fundamental Clash over Ho...   \n",
       "4    President Obama Vetoes 9/11 Victims Bill, Sett...   \n",
       "..                                                 ...   \n",
       "177  Hillary’s TOP Donor Country Just Auctioned Off...   \n",
       "178  Cavuto Just Exposed Lester Holt's Lies During ...   \n",
       "179  The AP, In 2004, Said Your Boy Obama Was BORN ...   \n",
       "180  People Noticed Something Odd About Hillary's O...   \n",
       "181  People Noticed Something Odd About Hillary’s O...   \n",
       "\n",
       "                                                  text  \\\n",
       "0    On Saturday, September 17 at 8:30 pm EST, an e...   \n",
       "1    Less than a day after protests over the police...   \n",
       "2    Obama To UN: ‘Giving Up Liberty, Enhances Secu...   \n",
       "3    Getty Images Wealth Of Nations Trump vs. Clint...   \n",
       "4    President Obama today vetoed a bill that would...   \n",
       "..                                                 ...   \n",
       "177  Hillary’s TOP Donor Country Just Auctioned Off...   \n",
       "178  Advertisement - story continues below\\n\\nThe f...   \n",
       "179  Well THAT’S Weird. If the Birther movement is ...   \n",
       "180  \\n\\nThere’s a lot to be discussed about last n...   \n",
       "181  People Noticed Something Odd About Hillary’s O...   \n",
       "\n",
       "                                 source news_type  contain_movies  \\\n",
       "0                http://eaglerising.com      Real               0   \n",
       "1                        http://abcn.ws      Real               0   \n",
       "2              http://rightwingnews.com      Real               1   \n",
       "3                      http://politi.co      Real               0   \n",
       "4                        http://abcn.ws      Real               0   \n",
       "..                                  ...       ...             ...   \n",
       "177            http://rightwingnews.com      Fake               0   \n",
       "178      http://conservativetribune.com      Fake               1   \n",
       "179               http://clashdaily.com      Fake               0   \n",
       "180  http://www.thepoliticalinsider.com      Fake               0   \n",
       "181            http://rightwingnews.com      Fake               0   \n",
       "\n",
       "     contain_images  \n",
       "0                 1  \n",
       "1                 1  \n",
       "2                 1  \n",
       "3                 1  \n",
       "4                 1  \n",
       "..              ...  \n",
       "177               1  \n",
       "178               1  \n",
       "179               1  \n",
       "180               1  \n",
       "181               1  \n",
       "\n",
       "[182 rows x 6 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Buzzfeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ecebb04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create fake title word columns\n",
    "# for word in fake_title_words:\n",
    "#     col_name = f\"fake_title_{word}\"\n",
    "#     Buzzfeed_title[col_name] = Buzzfeed_title['title'].apply(lambda x: count_word(x, word))\n",
    "\n",
    "# # Create real title word columns\n",
    "# for word in real_title_words:\n",
    "#     col_name = f\"real_title_{word}\"\n",
    "#     Buzzfeed_title[col_name] = Buzzfeed_title['title'].apply(lambda x: count_word(x, word))\n",
    "    \n",
    "\n",
    "# # Create fake body word columns\n",
    "# for word in fake_body_words:\n",
    "#     col_name = f\"fake_body_{word}\"\n",
    "#     Buzzfeed_body[col_name] = Buzzfeed_body['text'].apply(lambda x: count_word(x, word))\n",
    "\n",
    "# # Create real body word columns\n",
    "# for word in real_body_words:\n",
    "#     col_name = f\"real_body_{word}\"\n",
    "#     Buzzfeed_body[col_name] = Buzzfeed_body['text'].apply(lambda x: count_word(x, word))\n",
    "\n",
    "# Create fake title word columns\n",
    "for word in fake_title_words:\n",
    "    col_name = f\"fake_title_{word}\"\n",
    "    Buzzfeed_title[col_name] = Buzzfeed_title['title'].apply(lambda x: has_word(x, word))\n",
    "\n",
    "# Create real title word columns\n",
    "for word in real_title_words:\n",
    "    col_name = f\"real_title_{word}\"\n",
    "    Buzzfeed_title[col_name] = Buzzfeed_title['title'].apply(lambda x: has_word(x, word))\n",
    "    \n",
    "\n",
    "# Create fake body word columns\n",
    "for word in fake_body_words:\n",
    "    col_name = f\"fake_body_{word}\"\n",
    "    Buzzfeed_body[col_name] = Buzzfeed_body['text'].apply(lambda x: has_word(x, word))\n",
    "\n",
    "# Create real body word columns\n",
    "for word in real_body_words:\n",
    "    col_name = f\"real_body_{word}\"\n",
    "    Buzzfeed_body[col_name] = Buzzfeed_body['text'].apply(lambda x: has_word(x, word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "38ce0751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news_type</th>\n",
       "      <th>contain_movies</th>\n",
       "      <th>contain_images</th>\n",
       "      <th>fake_title_hillari</th>\n",
       "      <th>fake_title_clinton</th>\n",
       "      <th>fake_title_obama</th>\n",
       "      <th>fake_title_freedom</th>\n",
       "      <th>fake_title_daili</th>\n",
       "      <th>real_title_trump</th>\n",
       "      <th>real_title_clinton</th>\n",
       "      <th>real_title_donald</th>\n",
       "      <th>real_title_debat</th>\n",
       "      <th>real_title_obama</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   news_type  contain_movies  contain_images  fake_title_hillari  \\\n",
       "0          1               0               1                   0   \n",
       "1          1               0               1                   0   \n",
       "2          1               1               1                   0   \n",
       "\n",
       "   fake_title_clinton  fake_title_obama  fake_title_freedom  fake_title_daili  \\\n",
       "0                   0                 0                   0                 0   \n",
       "1                   0                 0                   0                 0   \n",
       "2                   0                 0                   0                 0   \n",
       "\n",
       "   real_title_trump  real_title_clinton  real_title_donald  real_title_debat  \\\n",
       "0                 0                   0                  0                 0   \n",
       "1                 0                   0                  0                 0   \n",
       "2                 0                   0                  0                 0   \n",
       "\n",
       "   real_title_obama  \n",
       "0                 0  \n",
       "1                 0  \n",
       "2                 0  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show new columns\n",
    "# Start from your Buzzfeed_title DataFrame\n",
    "title = Buzzfeed_title.copy()\n",
    "\n",
    "# Drop columns that shouldn't be used as predictors\n",
    "title = title.drop(columns=['title', 'text', 'source'])\n",
    "\n",
    "# # Convert 'source' to categorical (one-hot encoding)\n",
    "# title = pd.get_dummies(title, columns=['source'], drop_first=True)\n",
    "\n",
    "# Encode the target variable (news_type)\n",
    "le = LabelEncoder()\n",
    "title['news_type'] = le.fit_transform(title['news_type'])\n",
    "\n",
    "title.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f422d474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news_type</th>\n",
       "      <th>contain_movies</th>\n",
       "      <th>contain_images</th>\n",
       "      <th>fake_body_clinton</th>\n",
       "      <th>fake_body_hillari</th>\n",
       "      <th>fake_body_trump</th>\n",
       "      <th>fake_body_peopl</th>\n",
       "      <th>fake_body_just</th>\n",
       "      <th>real_body_trump</th>\n",
       "      <th>real_body_said</th>\n",
       "      <th>real_body_clinton</th>\n",
       "      <th>real_body_say</th>\n",
       "      <th>real_body_debat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   news_type  contain_movies  contain_images  fake_body_clinton  \\\n",
       "0          1               0               1                  0   \n",
       "1          1               0               1                  0   \n",
       "2          1               1               1                  0   \n",
       "\n",
       "   fake_body_hillari  fake_body_trump  fake_body_peopl  fake_body_just  \\\n",
       "0                  0                0                0               1   \n",
       "1                  0                0                0               0   \n",
       "2                  0                0                0               1   \n",
       "\n",
       "   real_body_trump  real_body_said  real_body_clinton  real_body_say  \\\n",
       "0                0               1                  0              1   \n",
       "1                0               1                  0              1   \n",
       "2                0               1                  0              1   \n",
       "\n",
       "   real_body_debat  \n",
       "0                0  \n",
       "1                0  \n",
       "2                0  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show new columns\n",
    "# Start from your Buzzfeed_body DataFrame\n",
    "body = Buzzfeed_body.copy()\n",
    "\n",
    "# Drop columns that shouldn't be used as predictors\n",
    "body = body.drop(columns=['title', 'text','source'])\n",
    "\n",
    "# # Convert 'source' to categorical (one-hot encoding)\n",
    "# body = pd.get_dummies(body, columns=['source'], drop_first=True)\n",
    "\n",
    "# Encode the target variable (news_type)\n",
    "le = LabelEncoder()\n",
    "body['news_type'] = le.fit_transform(body['news_type'])\n",
    "\n",
    "body.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d28ef67f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features (Forward):\n",
      "['news_type', 'contain_movies', 'contain_images', 'fake_title_hillari', 'fake_title_clinton', 'fake_title_obama', 'fake_title_freedom', 'fake_title_daili', 'real_title_trump', 'real_title_clinton']\n"
     ]
    }
   ],
   "source": [
    "# Define features and target\n",
    "X = title\n",
    "y = title['news_type']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression model\n",
    "lr = LogisticRegression(max_iter=500)\n",
    "\n",
    "# Forward Selection (choose 10 best features)\n",
    "sfs_forward = SFS(lr,\n",
    "                  k_features=10,\n",
    "                  forward=True,\n",
    "                  floating=False,\n",
    "                  scoring='accuracy',\n",
    "                  cv=5)\n",
    "\n",
    "sfs_forward = sfs_forward.fit(X_train, y_train)\n",
    "\n",
    "print(\"Selected Features (Forward):\")\n",
    "print(list(sfs_forward.k_feature_names_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "20dd0a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Model Accuracy: 1.0000\n",
      "Selected Feature Model Accuracy: 1.0000\n",
      "Accuracy Difference (SFS - Full): 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Full Model (all features) \n",
    "lr_full = LogisticRegression(max_iter=1000, solver='liblinear')\n",
    "lr_full.fit(X_train, y_train)\n",
    "\n",
    "y_pred_full = lr_full.predict(X_test)\n",
    "acc_full = accuracy_score(y_test, y_pred_full)\n",
    "print(f\"Full Model Accuracy: {acc_full:.4f}\")\n",
    "\n",
    "# Selected Feature Model (using SFS) \n",
    "selected_features = list(sfs_forward.k_feature_names_)\n",
    "X_train_sfs = X_train[selected_features]\n",
    "X_test_sfs = X_test[selected_features]\n",
    "\n",
    "lr_sfs = LogisticRegression(max_iter=1000, solver='liblinear')\n",
    "lr_sfs.fit(X_train_sfs, y_train)\n",
    "\n",
    "y_pred_sfs = lr_sfs.predict(X_test_sfs)\n",
    "acc_sfs = accuracy_score(y_test, y_pred_sfs)\n",
    "print(f\"Selected Feature Model Accuracy: {acc_sfs:.4f}\")\n",
    "\n",
    "# Comparison \n",
    "improvement = acc_sfs - acc_full\n",
    "print(f\"Accuracy Difference (SFS - Full): {improvement:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "eb871917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.5\n",
      "1    0.5\n",
      "Name: news_type, dtype: float64\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# Check class balance\n",
    "print(title['news_type'].value_counts(normalize=True))\n",
    "\n",
    "# Check duplicates / leakage\n",
    "print(Buzzfeed.duplicated(subset=['title','text']).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d3819211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV accuracies: [1. 1. 1. 1. 1.]\n",
      "Mean CV accuracy: 1.000 ± 0.000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "lr = LogisticRegression(max_iter=2000, solver='liblinear')\n",
    "\n",
    "scores = cross_val_score(lr, X, y, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "print(\"CV accuracies:\", scores)\n",
    "print(\"Mean CV accuracy: {:.3f} ± {:.3f}\".format(scores.mean(), scores.std()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c8363018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Preprocessing Functions\n",
    "\n",
    "ps = PorterStemmer()\n",
    "wst = WhitespaceTokenizer()\n",
    "\n",
    "# Lowercase\n",
    "def lower_func(x):\n",
    "    return x.lower()\n",
    "\n",
    "# Remove numbers\n",
    "def remove_number_func(x): \n",
    "    return ''.join([a for a in x if not a.isdigit()])\n",
    "\n",
    "# Remove punctuation\n",
    "def remove_punc_func(x):\n",
    "    return ''.join([a for a in x if a not in string.punctuation])\n",
    "\n",
    "# Remove special characters\n",
    "def remove_spec_char_func(x):\n",
    "    return ''.join([a for a in x if a.isalnum() or a == ' '])\n",
    "\n",
    "# Remove English stopwords (using sklearn)\n",
    "def remove_stopwords(x):\n",
    "    new = []\n",
    "    for a in x.split():\n",
    "        if a not in ENGLISH_STOP_WORDS:\n",
    "            new.append(a)\n",
    "    return \" \".join(new)\n",
    "\n",
    "# Stemming\n",
    "def stem_func(x):\n",
    "    wordlist = word_tokenize(x)\n",
    "    psstem = [ps.stem(a) for a in wordlist]\n",
    "    return ' '.join(psstem)\n",
    "\n",
    "# Remove extra whitespaces\n",
    "def remove_whitespace_func(x):\n",
    "    return(wst.tokenize(x))\n",
    "\n",
    "# Function composition helper\n",
    "def compose(f, g):\n",
    "    return lambda x: f(g(x))\n",
    "\n",
    "# Final preprocessing pipeline\n",
    "final = compose(\n",
    "    compose(\n",
    "        compose(\n",
    "            compose(\n",
    "                compose(\n",
    "                    compose(remove_whitespace_func, stem_func),\n",
    "                    remove_stopwords\n",
    "                ),\n",
    "                remove_spec_char_func\n",
    "            ),\n",
    "            remove_punc_func\n",
    "        ),\n",
    "        remove_number_func\n",
    "    ),\n",
    "    lower_func\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "71ac796f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13 15]\n",
      " [ 3 24]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fake       0.81      0.46      0.59        28\n",
      "        Real       0.62      0.89      0.73        27\n",
      "\n",
      "    accuracy                           0.67        55\n",
      "   macro avg       0.71      0.68      0.66        55\n",
      "weighted avg       0.72      0.67      0.66        55\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split features and target\n",
    "X = Buzzfeed['title']  \n",
    "y = Buzzfeed['news_type']\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Preprocessing + RandomForest pipeline\n",
    "pp = Pipeline([\n",
    "    ('bow', CountVectorizer(analyzer=final)),  # final is your preprocessing function\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "# Fit model\n",
    "pp.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "predictions = pp.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3fee47c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19  9]\n",
      " [ 8 19]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fake       0.70      0.68      0.69        28\n",
      "        Real       0.68      0.70      0.69        27\n",
      "\n",
      "    accuracy                           0.69        55\n",
      "   macro avg       0.69      0.69      0.69        55\n",
      "weighted avg       0.69      0.69      0.69        55\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split features and target\n",
    "X = Buzzfeed['text']  \n",
    "y = Buzzfeed['news_type']\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Preprocessing + RandomForest pipeline\n",
    "pp = Pipeline([\n",
    "    ('bow', CountVectorizer(analyzer=final)),  # final is your preprocessing function\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "# Fit model\n",
    "pp.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "predictions = pp.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9aaef665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Feature</th>\n",
       "      <th>Model</th>\n",
       "      <th>Body</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>0.690909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaiveBayes</td>\n",
       "      <td>0.763636</td>\n",
       "      <td>0.618182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.690909</td>\n",
       "      <td>0.672727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.654545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Feature               Model      Body     Title\n",
       "0        LogisticRegression  0.781818  0.690909\n",
       "1                NaiveBayes  0.763636  0.618182\n",
       "2              RandomForest  0.690909  0.672727\n",
       "3                       SVM  0.818182  0.654545"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define models to compare\n",
    "models = {\n",
    "    \"RandomForest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"LogisticRegression\": LogisticRegression(max_iter=500, random_state=42),\n",
    "    \"NaiveBayes\": MultinomialNB(),\n",
    "    \"SVM\": SVC(kernel='linear', random_state=42)\n",
    "}\n",
    "\n",
    "# Feature types\n",
    "feature_types = {\n",
    "    \"Title\": Buzzfeed['title'],\n",
    "    \"Body\": Buzzfeed['text']\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for feat_name, X in feature_types.items():\n",
    "    y = Buzzfeed['news_type']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        pipeline = Pipeline([\n",
    "            ('bow', CountVectorizer(analyzer=final)),\n",
    "            ('tfidf', TfidfTransformer()),\n",
    "            ('clf', model)\n",
    "        ])\n",
    "        \n",
    "        pipeline.fit(X_train, y_train)\n",
    "        preds = pipeline.predict(X_test)\n",
    "        \n",
    "        results.append({\n",
    "            \"Feature\": feat_name,\n",
    "            \"Model\": model_name,\n",
    "            \"Accuracy\": accuracy_score(y_test, preds),\n",
    "            \"Precision\": precision_score(y_test, preds, pos_label='Real'),\n",
    "            \"Recall\": recall_score(y_test, preds, pos_label='Real'),\n",
    "            \"F1\": f1_score(y_test, preds, pos_label='Real')\n",
    "        })\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Pivot table to show only accuracy\n",
    "accuracy_df = results_df.pivot(index='Model', columns='Feature', values='Accuracy')\n",
    "accuracy_df = accuracy_df.reset_index()\n",
    "accuracy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "75d5ca7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Feature</th>\n",
       "      <th>Model</th>\n",
       "      <th>Body</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>0.690909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaiveBayes</td>\n",
       "      <td>0.763636</td>\n",
       "      <td>0.618182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.690909</td>\n",
       "      <td>0.672727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.654545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Feature               Model      Body     Title\n",
       "0        LogisticRegression  0.781818  0.690909\n",
       "1                NaiveBayes  0.763636  0.618182\n",
       "2              RandomForest  0.690909  0.672727\n",
       "3                       SVM  0.818182  0.654545"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pivot table to show only accuracy\n",
    "accuracy_df = results_df.pivot(index='Model', columns='Feature', values='Accuracy')\n",
    "accuracy_df = accuracy_df.reset_index()\n",
    "accuracy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "27233cd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/svm_body_model.pkl']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lambda cause error to download  \n",
    "def finals(text):\n",
    "    text = lower_func(text)\n",
    "    text = remove_number_func(text)\n",
    "    text = remove_punc_func(text)\n",
    "    text = remove_spec_char_func(text)\n",
    "    text = remove_stopwords(text)\n",
    "    text = stem_func(text)\n",
    "    text = ' '.join(remove_whitespace_func(text))\n",
    "    return text\n",
    "\n",
    "# Split features and target\n",
    "X = Buzzfeed['text']  \n",
    "y = Buzzfeed['news_type']\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Preprocessing + SVM pipeline\n",
    "svm_pipeline = Pipeline([\n",
    "    ('bow', CountVectorizer(analyzer=finals)),  # your preprocessing function\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('classifier', SVC(kernel='linear', random_state=42))\n",
    "])\n",
    "\n",
    "# Fit model\n",
    "svm_pipeline.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Path to folder\n",
    "os.makedirs('data', exist_ok=True)\n",
    "\n",
    "# Save your trained pipeline inside the data folder\n",
    "joblib.dump(svm_pipeline, 'data/svm_body_model.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
