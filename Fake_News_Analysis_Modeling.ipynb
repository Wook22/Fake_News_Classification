{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "423e590b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import string\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize, WhitespaceTokenizer\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import joblib\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1ed7e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "Buzzfeed = pd.read_csv('data/Buzzfeed_data.csv')\n",
    "Buzzfeed_title = Buzzfeed.copy()\n",
    "Buzzfeed_body = Buzzfeed.copy()\n",
    "\n",
    "top1 = pd.read_csv('data/top1_fake_title.csv').head(5)  # top 5 fake title words\n",
    "top2 = pd.read_csv('data/top2_real_title.csv').head(5)  # top 5 real title words\n",
    "top3 = pd.read_csv('data/top3_fake_body.csv').head(5)   # top 5 fake body words\n",
    "top4 = pd.read_csv('data/top4_real_body.csv').head(5)   # top 5 real body words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92165811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert top words to list\n",
    "fake_title_words = top1['word'].tolist()\n",
    "real_title_words = top2['word'].tolist()\n",
    "fake_body_words = top3['word'].tolist()\n",
    "real_body_words = top4['word'].tolist()\n",
    "    \n",
    "\n",
    "# Helper to count occurrences of a word\n",
    "# def count_word(text, word):\n",
    "#     if isinstance(text, str):\n",
    "#         return len(re.findall(rf'\\b{word}\\b', text))\n",
    "#     else:\n",
    "#         return 0\n",
    "\n",
    "def has_word(text, word):\n",
    "    if isinstance(text, str):\n",
    "        return 1 if re.search(rf'\\b{word}\\b', text) else 0\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ff250eb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>news_type</th>\n",
       "      <th>contain_movies</th>\n",
       "      <th>contain_images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Another Terrorist Attack in NYC…Why Are we STI...</td>\n",
       "      <td>On Saturday, September 17 at 8:30 pm EST, an e...</td>\n",
       "      <td>http://eaglerising.com</td>\n",
       "      <td>Real</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Donald Trump: Drugs a 'Very, Very Big Factor' ...</td>\n",
       "      <td>Less than a day after protests over the police...</td>\n",
       "      <td>http://abcn.ws</td>\n",
       "      <td>Real</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Obama To UN: ‘Giving Up Liberty, Enhances Secu...</td>\n",
       "      <td>Obama To UN: ‘Giving Up Liberty, Enhances Secu...</td>\n",
       "      <td>http://rightwingnews.com</td>\n",
       "      <td>Real</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trump vs. Clinton: A Fundamental Clash over Ho...</td>\n",
       "      <td>Getty Images Wealth Of Nations Trump vs. Clint...</td>\n",
       "      <td>http://politi.co</td>\n",
       "      <td>Real</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>President Obama Vetoes 9/11 Victims Bill, Sett...</td>\n",
       "      <td>President Obama today vetoed a bill that would...</td>\n",
       "      <td>http://abcn.ws</td>\n",
       "      <td>Real</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>Hillary’s TOP Donor Country Just Auctioned Off...</td>\n",
       "      <td>Hillary’s TOP Donor Country Just Auctioned Off...</td>\n",
       "      <td>http://rightwingnews.com</td>\n",
       "      <td>Fake</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>Cavuto Just Exposed Lester Holt's Lies During ...</td>\n",
       "      <td>Advertisement - story continues below\\n\\nThe f...</td>\n",
       "      <td>http://conservativetribune.com</td>\n",
       "      <td>Fake</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>The AP, In 2004, Said Your Boy Obama Was BORN ...</td>\n",
       "      <td>Well THAT’S Weird. If the Birther movement is ...</td>\n",
       "      <td>http://clashdaily.com</td>\n",
       "      <td>Fake</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>People Noticed Something Odd About Hillary's O...</td>\n",
       "      <td>\\n\\nThere’s a lot to be discussed about last n...</td>\n",
       "      <td>http://www.thepoliticalinsider.com</td>\n",
       "      <td>Fake</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>People Noticed Something Odd About Hillary’s O...</td>\n",
       "      <td>People Noticed Something Odd About Hillary’s O...</td>\n",
       "      <td>http://rightwingnews.com</td>\n",
       "      <td>Fake</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>182 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "0    Another Terrorist Attack in NYC…Why Are we STI...   \n",
       "1    Donald Trump: Drugs a 'Very, Very Big Factor' ...   \n",
       "2    Obama To UN: ‘Giving Up Liberty, Enhances Secu...   \n",
       "3    Trump vs. Clinton: A Fundamental Clash over Ho...   \n",
       "4    President Obama Vetoes 9/11 Victims Bill, Sett...   \n",
       "..                                                 ...   \n",
       "177  Hillary’s TOP Donor Country Just Auctioned Off...   \n",
       "178  Cavuto Just Exposed Lester Holt's Lies During ...   \n",
       "179  The AP, In 2004, Said Your Boy Obama Was BORN ...   \n",
       "180  People Noticed Something Odd About Hillary's O...   \n",
       "181  People Noticed Something Odd About Hillary’s O...   \n",
       "\n",
       "                                                  text  \\\n",
       "0    On Saturday, September 17 at 8:30 pm EST, an e...   \n",
       "1    Less than a day after protests over the police...   \n",
       "2    Obama To UN: ‘Giving Up Liberty, Enhances Secu...   \n",
       "3    Getty Images Wealth Of Nations Trump vs. Clint...   \n",
       "4    President Obama today vetoed a bill that would...   \n",
       "..                                                 ...   \n",
       "177  Hillary’s TOP Donor Country Just Auctioned Off...   \n",
       "178  Advertisement - story continues below\\n\\nThe f...   \n",
       "179  Well THAT’S Weird. If the Birther movement is ...   \n",
       "180  \\n\\nThere’s a lot to be discussed about last n...   \n",
       "181  People Noticed Something Odd About Hillary’s O...   \n",
       "\n",
       "                                 source news_type  contain_movies  \\\n",
       "0                http://eaglerising.com      Real               0   \n",
       "1                        http://abcn.ws      Real               0   \n",
       "2              http://rightwingnews.com      Real               1   \n",
       "3                      http://politi.co      Real               0   \n",
       "4                        http://abcn.ws      Real               0   \n",
       "..                                  ...       ...             ...   \n",
       "177            http://rightwingnews.com      Fake               0   \n",
       "178      http://conservativetribune.com      Fake               1   \n",
       "179               http://clashdaily.com      Fake               0   \n",
       "180  http://www.thepoliticalinsider.com      Fake               0   \n",
       "181            http://rightwingnews.com      Fake               0   \n",
       "\n",
       "     contain_images  \n",
       "0                 1  \n",
       "1                 1  \n",
       "2                 1  \n",
       "3                 1  \n",
       "4                 1  \n",
       "..              ...  \n",
       "177               1  \n",
       "178               1  \n",
       "179               1  \n",
       "180               1  \n",
       "181               1  \n",
       "\n",
       "[182 rows x 6 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Buzzfeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecebb04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create fake title word columns\n",
    "for word in fake_title_words:\n",
    "    col_name = f\"fake_title_{word}\"\n",
    "    Buzzfeed_title[col_name] = Buzzfeed_title['title'].apply(lambda x: has_word(x, word))\n",
    "\n",
    "# Create real title word columns\n",
    "for word in real_title_words:\n",
    "    col_name = f\"real_title_{word}\"\n",
    "    Buzzfeed_title[col_name] = Buzzfeed_title['title'].apply(lambda x: has_word(x, word))\n",
    "    \n",
    "\n",
    "# Create fake body word columns\n",
    "for word in fake_body_words:\n",
    "    col_name = f\"fake_body_{word}\"\n",
    "    Buzzfeed_body[col_name] = Buzzfeed_body['text'].apply(lambda x: has_word(x, word))\n",
    "\n",
    "# Create real body word columns\n",
    "for word in real_body_words:\n",
    "    col_name = f\"real_body_{word}\"\n",
    "    Buzzfeed_body[col_name] = Buzzfeed_body['text'].apply(lambda x: has_word(x, word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ce0751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news_type</th>\n",
       "      <th>contain_movies</th>\n",
       "      <th>contain_images</th>\n",
       "      <th>fake_title_hillari</th>\n",
       "      <th>fake_title_clinton</th>\n",
       "      <th>fake_title_obama</th>\n",
       "      <th>fake_title_freedom</th>\n",
       "      <th>fake_title_daili</th>\n",
       "      <th>real_title_trump</th>\n",
       "      <th>real_title_clinton</th>\n",
       "      <th>real_title_donald</th>\n",
       "      <th>real_title_debat</th>\n",
       "      <th>real_title_obama</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   news_type  contain_movies  contain_images  fake_title_hillari  \\\n",
       "0          1               0               1                   0   \n",
       "1          1               0               1                   0   \n",
       "2          1               1               1                   0   \n",
       "\n",
       "   fake_title_clinton  fake_title_obama  fake_title_freedom  fake_title_daili  \\\n",
       "0                   0                 0                   0                 0   \n",
       "1                   0                 0                   0                 0   \n",
       "2                   0                 0                   0                 0   \n",
       "\n",
       "   real_title_trump  real_title_clinton  real_title_donald  real_title_debat  \\\n",
       "0                 0                   0                  0                 0   \n",
       "1                 0                   0                  0                 0   \n",
       "2                 0                   0                  0                 0   \n",
       "\n",
       "   real_title_obama  \n",
       "0                 0  \n",
       "1                 0  \n",
       "2                 0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show new columns\n",
    "# Start from your Buzzfeed_title DataFrame\n",
    "title = Buzzfeed_title.copy()\n",
    "\n",
    "# Drop columns that shouldn't be used as predictors\n",
    "title = title.drop(columns=['title', 'text', 'source'])\n",
    "\n",
    "# # Convert 'source' to categorical (one-hot encoding)\n",
    "# title = pd.get_dummies(title, columns=['source'], drop_first=True)\n",
    "\n",
    "# Encode the target variable (news_type)\n",
    "le = LabelEncoder()\n",
    "title['news_type'] = le.fit_transform(title['news_type'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f422d474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news_type</th>\n",
       "      <th>contain_movies</th>\n",
       "      <th>contain_images</th>\n",
       "      <th>fake_body_clinton</th>\n",
       "      <th>fake_body_hillari</th>\n",
       "      <th>fake_body_trump</th>\n",
       "      <th>fake_body_peopl</th>\n",
       "      <th>fake_body_just</th>\n",
       "      <th>real_body_trump</th>\n",
       "      <th>real_body_said</th>\n",
       "      <th>real_body_clinton</th>\n",
       "      <th>real_body_say</th>\n",
       "      <th>real_body_debat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   news_type  contain_movies  contain_images  fake_body_clinton  \\\n",
       "0          1               0               1                  0   \n",
       "1          1               0               1                  0   \n",
       "2          1               1               1                  0   \n",
       "\n",
       "   fake_body_hillari  fake_body_trump  fake_body_peopl  fake_body_just  \\\n",
       "0                  0                0                0               1   \n",
       "1                  0                0                0               0   \n",
       "2                  0                0                0               1   \n",
       "\n",
       "   real_body_trump  real_body_said  real_body_clinton  real_body_say  \\\n",
       "0                0               1                  0              1   \n",
       "1                0               1                  0              1   \n",
       "2                0               1                  0              1   \n",
       "\n",
       "   real_body_debat  \n",
       "0                0  \n",
       "1                0  \n",
       "2                0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show new columns\n",
    "# Start from your Buzzfeed_body DataFrame\n",
    "body = Buzzfeed_body.copy()\n",
    "\n",
    "# Drop columns that shouldn't be used as predictors\n",
    "body = body.drop(columns=['title', 'text','source'])\n",
    "\n",
    "# # Convert 'source' to categorical (one-hot encoding)\n",
    "# body = pd.get_dummies(body, columns=['source'], drop_first=True)\n",
    "\n",
    "# Encode the target variable (news_type)\n",
    "le = LabelEncoder()\n",
    "body['news_type'] = le.fit_transform(body['news_type'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8307033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target\n",
    "X = title.drop(columns=['news_type']) \n",
    "y = title['news_type']\n",
    "\n",
    "# Now perform the train/test split:\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a94c8b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features (Forward):\n",
      "['contain_movies', 'contain_images', 'fake_title_hillari', 'fake_title_clinton', 'fake_title_obama', 'fake_title_freedom', 'fake_title_daili', 'real_title_trump', 'real_title_clinton', 'real_title_donald']\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression model (Forward Selection setup remains the same)\n",
    "lr = LogisticRegression(max_iter=500)\n",
    "\n",
    "# Forward Selection (choose 10 best features)\n",
    "# k_features is set to 10 here, which means 10 non-'news_type' features will be selected\n",
    "sfs_forward = SFS(\n",
    "    lr,\n",
    "    k_features=10,\n",
    "    forward=True,\n",
    "    floating=False,\n",
    "    scoring='accuracy',\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "sfs_forward = sfs_forward.fit(X_train, y_train)\n",
    "\n",
    "print(\"Selected Features (Forward):\")\n",
    "print(list(sfs_forward.k_feature_names_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3cfd2bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Model Accuracy (Corrected): 0.7297\n",
      "Selected Feature Model Accuracy (Corrected): 0.7297\n",
      "Accuracy Difference (SFS - Full): 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Full Model (all features, excluding news_type)\n",
    "lr_full = LogisticRegression(max_iter=1000, solver='liblinear')\n",
    "lr_full.fit(X_train, y_train)\n",
    "\n",
    "y_pred_full = lr_full.predict(X_test)\n",
    "acc_full = accuracy_score(y_test, y_pred_full)\n",
    "\n",
    "print(f\"Full Model Accuracy (Corrected): {acc_full:.4f}\")\n",
    "\n",
    "# Selected Feature Model (using SFS)\n",
    "selected_features = list(sfs_forward.k_feature_names_)\n",
    "\n",
    "# X_train and X_test are now subsetted correctly using only the selected features\n",
    "X_train_sfs = X_train[selected_features]\n",
    "X_test_sfs = X_test[selected_features]\n",
    "\n",
    "lr_sfs = LogisticRegression(max_iter=1000, solver='liblinear')\n",
    "lr_sfs.fit(X_train_sfs, y_train)\n",
    "\n",
    "y_pred_sfs = lr_sfs.predict(X_test_sfs)\n",
    "acc_sfs = accuracy_score(y_test, y_pred_sfs)\n",
    "\n",
    "print(f\"Selected Feature Model Accuracy (Corrected): {acc_sfs:.4f}\")\n",
    "\n",
    "improvement = acc_sfs - acc_full\n",
    "print(f\"Accuracy Difference (SFS - Full): {improvement:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb871917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target\n",
    "X = body.drop(columns=['news_type']) \n",
    "y = body['news_type']\n",
    "\n",
    "# Now perform the train/test split:\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b64fc1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Model Accuracy (Corrected): 0.6757\n",
      "Selected Feature Model Accuracy (Corrected): 0.6757\n",
      "Accuracy Difference (SFS - Full): 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression model (Forward Selection setup remains the same)\n",
    "lr = LogisticRegression(max_iter=500)\n",
    "\n",
    "# Forward Selection (choose 10 best features)\n",
    "# k_features is set to 10 here, which means 10 non-'news_type' features will be selected\n",
    "sfs_forward = SFS(\n",
    "    lr,\n",
    "    k_features=10,\n",
    "    forward=True,\n",
    "    floating=False,\n",
    "    scoring='accuracy',\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "sfs_forward = sfs_forward.fit(X_train, y_train)\n",
    "\n",
    "# Full Model (all features, excluding news_type)\n",
    "lr_full = LogisticRegression(max_iter=1000, solver='liblinear')\n",
    "lr_full.fit(X_train, y_train)\n",
    "\n",
    "y_pred_full = lr_full.predict(X_test)\n",
    "acc_full = accuracy_score(y_test, y_pred_full)\n",
    "\n",
    "print(f\"Full Model Accuracy (Corrected): {acc_full:.4f}\")\n",
    "\n",
    "# Selected Feature Model (using SFS)\n",
    "selected_features = list(sfs_forward.k_feature_names_)\n",
    "\n",
    "# X_train and X_test are now subsetted correctly using only the selected features\n",
    "X_train_sfs = X_train[selected_features]\n",
    "X_test_sfs = X_test[selected_features]\n",
    "\n",
    "lr_sfs = LogisticRegression(max_iter=1000, solver='liblinear')\n",
    "lr_sfs.fit(X_train_sfs, y_train)\n",
    "\n",
    "y_pred_sfs = lr_sfs.predict(X_test_sfs)\n",
    "acc_sfs = accuracy_score(y_test, y_pred_sfs)\n",
    "\n",
    "print(f\"Selected Feature Model Accuracy (Corrected): {acc_sfs:.4f}\")\n",
    "\n",
    "improvement = acc_sfs - acc_full\n",
    "print(f\"Accuracy Difference (SFS - Full): {improvement:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9a32faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model training and evaluation...\n"
     ]
    }
   ],
   "source": [
    "X = title.drop(columns=['news_type']) \n",
    "y = title['news_type']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# --- Define Models ---\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, solver='liblinear', random_state=42),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"K-Nearest Neighbors (k=5)\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"Support Vector Machine (Linear)\": SVC(kernel='linear', random_state=42)\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "# --- Train, Predict, and Evaluate ---\n",
    "print(\"Running model training and evaluation...\")\n",
    "for name, model in models.items():\n",
    "    # Train the full model on X_train\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the hold-out test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Store results\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": accuracy\n",
    "    })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0cffe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Model Accuracy Comparison (Word-Presence Features) ---\n",
      "                             Model  Accuracy\n",
      "0              Logistic Regression  0.702703\n",
      "1                    Decision Tree  0.702703\n",
      "2  Support Vector Machine (Linear)  0.702703\n",
      "3        K-Nearest Neighbors (k=5)  0.513514\n"
     ]
    }
   ],
   "source": [
    "# --- Create Comparison DataFrame ---\n",
    "comparison_df = pd.DataFrame(results).sort_values(by='Accuracy', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"--- Model Accuracy Comparison (Word-Presence Features) ---\")\n",
    "print(comparison_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c612a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import tensorflow as tf\n",
    "    print(f\"TensorFlow is installed. Version: {tf.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"TensorFlow is NOT installed. You can install it using: pip install tensorflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29278006",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# 1. Split the data \n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(\n",
    "    Buzzfeed['title'], Buzzfeed['news_type'], test_size=0.2, random_state=42, stratify=Buzzfeed['news_type']\n",
    ")\n",
    "\n",
    "# 2. Tokenize the text \n",
    "max_words = 10000  # Vocabulary size\n",
    "tokenizer = Tokenizer(num_words=max_words, oov_token=\"<unk>\")\n",
    "tokenizer.fit_on_texts(X_train_raw)\n",
    "\n",
    "# 3. Convert text to sequences and pad\n",
    "maxlen = 20 # Maximum length for a title\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train_raw)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test_raw)\n",
    "\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=maxlen, padding='post', truncating='post')\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=maxlen, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f57b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "\n",
    "# Model parameters\n",
    "embedding_dim = 100\n",
    "\n",
    "# Build the LSTM model\n",
    "model = Sequential([\n",
    "    # Input layer: Turns index sequence into dense vectors (embeddings)\n",
    "    Embedding(max_words, embedding_dim, input_length=maxlen), \n",
    "    \n",
    "    # LSTM layer: The core recurrent layer to capture sequential information\n",
    "    LSTM(64), \n",
    "    \n",
    "    # Dropout for regularization (to prevent overfitting)\n",
    "    Dropout(0.5), \n",
    "    \n",
    "    # Output layer: Sigmoid activation for binary classification (Real/Fake)\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model (Using 10 epochs as a starting point)\n",
    "history = model.fit(\n",
    "    X_train_pad, \n",
    "    y_train, \n",
    "    epochs=10, \n",
    "    batch_size=32, \n",
    "    validation_data=(X_test_pad, y_test)\n",
    ")\n",
    "\n",
    "# Evaluate on the test set\n",
    "loss, accuracy = model.evaluate(X_test_pad, y_test, verbose=0)\n",
    "print(f\"\\nLSTM Model Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c8363018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Preprocessing Functions\n",
    "\n",
    "ps = PorterStemmer()\n",
    "wst = WhitespaceTokenizer()\n",
    "\n",
    "# Lowercase\n",
    "def lower_func(x):\n",
    "    return x.lower()\n",
    "\n",
    "# Remove numbers\n",
    "def remove_number_func(x): \n",
    "    return ''.join([a for a in x if not a.isdigit()])\n",
    "\n",
    "# Remove punctuation\n",
    "def remove_punc_func(x):\n",
    "    return ''.join([a for a in x if a not in string.punctuation])\n",
    "\n",
    "# Remove special characters\n",
    "def remove_spec_char_func(x):\n",
    "    return ''.join([a for a in x if a.isalnum() or a == ' '])\n",
    "\n",
    "# Remove English stopwords (using sklearn)\n",
    "def remove_stopwords(x):\n",
    "    new = []\n",
    "    for a in x.split():\n",
    "        if a not in ENGLISH_STOP_WORDS:\n",
    "            new.append(a)\n",
    "    return \" \".join(new)\n",
    "\n",
    "# Stemming\n",
    "def stem_func(x):\n",
    "    wordlist = word_tokenize(x)\n",
    "    psstem = [ps.stem(a) for a in wordlist]\n",
    "    return ' '.join(psstem)\n",
    "\n",
    "# Remove extra whitespaces\n",
    "def remove_whitespace_func(x):\n",
    "    return(wst.tokenize(x))\n",
    "\n",
    "# Function composition helper\n",
    "def compose(f, g):\n",
    "    return lambda x: f(g(x))\n",
    "\n",
    "# Final preprocessing pipeline\n",
    "final = compose(\n",
    "    compose(\n",
    "        compose(\n",
    "            compose(\n",
    "                compose(\n",
    "                    compose(remove_whitespace_func, stem_func),\n",
    "                    remove_stopwords\n",
    "                ),\n",
    "                remove_spec_char_func\n",
    "            ),\n",
    "            remove_punc_func\n",
    "        ),\n",
    "        remove_number_func\n",
    "    ),\n",
    "    lower_func\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d715471",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "71ac796f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13 15]\n",
      " [ 3 24]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fake       0.81      0.46      0.59        28\n",
      "        Real       0.62      0.89      0.73        27\n",
      "\n",
      "    accuracy                           0.67        55\n",
      "   macro avg       0.71      0.68      0.66        55\n",
      "weighted avg       0.72      0.67      0.66        55\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split features and target\n",
    "X = Buzzfeed['title']  \n",
    "y = Buzzfeed['news_type']\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Preprocessing + RandomForest pipeline\n",
    "pp = Pipeline([\n",
    "    ('bow', CountVectorizer(analyzer=final)),  # final is your preprocessing function\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "# Fit model\n",
    "pp.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "predictions = pp.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3fee47c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19  9]\n",
      " [ 8 19]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fake       0.70      0.68      0.69        28\n",
      "        Real       0.68      0.70      0.69        27\n",
      "\n",
      "    accuracy                           0.69        55\n",
      "   macro avg       0.69      0.69      0.69        55\n",
      "weighted avg       0.69      0.69      0.69        55\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split features and target\n",
    "X = Buzzfeed['text']  \n",
    "y = Buzzfeed['news_type']\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Preprocessing + RandomForest pipeline\n",
    "pp = Pipeline([\n",
    "    ('bow', CountVectorizer(analyzer=final)),  # final is your preprocessing function\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "# Fit model\n",
    "pp.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "predictions = pp.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9aaef665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Feature</th>\n",
       "      <th>Model</th>\n",
       "      <th>Body</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>0.690909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaiveBayes</td>\n",
       "      <td>0.763636</td>\n",
       "      <td>0.618182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.690909</td>\n",
       "      <td>0.672727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.654545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Feature               Model      Body     Title\n",
       "0        LogisticRegression  0.781818  0.690909\n",
       "1                NaiveBayes  0.763636  0.618182\n",
       "2              RandomForest  0.690909  0.672727\n",
       "3                       SVM  0.818182  0.654545"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define models to compare\n",
    "models = {\n",
    "    \"RandomForest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"LogisticRegression\": LogisticRegression(max_iter=500, random_state=42),\n",
    "    \"NaiveBayes\": MultinomialNB(),\n",
    "    \"SVM\": SVC(kernel='linear', random_state=42)\n",
    "}\n",
    "\n",
    "# Feature types\n",
    "feature_types = {\n",
    "    \"Title\": Buzzfeed['title'],\n",
    "    \"Body\": Buzzfeed['text']\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for feat_name, X in feature_types.items():\n",
    "    y = Buzzfeed['news_type']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        pipeline = Pipeline([\n",
    "            ('bow', CountVectorizer(analyzer=final)),\n",
    "            ('tfidf', TfidfTransformer()),\n",
    "            ('clf', model)\n",
    "        ])\n",
    "        \n",
    "        pipeline.fit(X_train, y_train)\n",
    "        preds = pipeline.predict(X_test)\n",
    "        \n",
    "        results.append({\n",
    "            \"Feature\": feat_name,\n",
    "            \"Model\": model_name,\n",
    "            \"Accuracy\": accuracy_score(y_test, preds),\n",
    "            \"Precision\": precision_score(y_test, preds, pos_label='Real'),\n",
    "            \"Recall\": recall_score(y_test, preds, pos_label='Real'),\n",
    "            \"F1\": f1_score(y_test, preds, pos_label='Real')\n",
    "        })\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Pivot table to show only accuracy\n",
    "accuracy_df = results_df.pivot(index='Model', columns='Feature', values='Accuracy')\n",
    "accuracy_df = accuracy_df.reset_index()\n",
    "accuracy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "75d5ca7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Feature</th>\n",
       "      <th>Model</th>\n",
       "      <th>Body</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>0.690909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaiveBayes</td>\n",
       "      <td>0.763636</td>\n",
       "      <td>0.618182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.690909</td>\n",
       "      <td>0.672727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.654545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Feature               Model      Body     Title\n",
       "0        LogisticRegression  0.781818  0.690909\n",
       "1                NaiveBayes  0.763636  0.618182\n",
       "2              RandomForest  0.690909  0.672727\n",
       "3                       SVM  0.818182  0.654545"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pivot table to show only accuracy\n",
    "accuracy_df = results_df.pivot(index='Model', columns='Feature', values='Accuracy')\n",
    "accuracy_df = accuracy_df.reset_index()\n",
    "accuracy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "27233cd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/svm_body_model.pkl']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lambda cause error to download  \n",
    "def finals(text):\n",
    "    text = lower_func(text)\n",
    "    text = remove_number_func(text)\n",
    "    text = remove_punc_func(text)\n",
    "    text = remove_spec_char_func(text)\n",
    "    text = remove_stopwords(text)\n",
    "    text = stem_func(text)\n",
    "    text = ' '.join(remove_whitespace_func(text))\n",
    "    return text\n",
    "\n",
    "# Split features and target\n",
    "X = Buzzfeed['text']  \n",
    "y = Buzzfeed['news_type']\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Preprocessing + SVM pipeline\n",
    "svm_pipeline = Pipeline([\n",
    "    ('bow', CountVectorizer(analyzer=finals)),  # your preprocessing function\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('classifier', SVC(kernel='linear', random_state=42))\n",
    "])\n",
    "\n",
    "# Fit model\n",
    "svm_pipeline.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Path to folder\n",
    "os.makedirs('data', exist_ok=True)\n",
    "\n",
    "# Save your trained pipeline inside the data folder\n",
    "joblib.dump(svm_pipeline, 'data/svm_body_model.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
